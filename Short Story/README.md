Short Story: Video-Language Pre-training based on Transformer Models
-
In this article, we begin with understanding the basic transformer architecture. Then continue to learn about various approaches for pre-training and fine-tuning methods used by transformer-based models for video training. We will also see various datasets available for video training. Then we have an overview of all the notable transformer models used for video training.

Medium Article: https://raghavadurs.medium.com/video-language-pre-training-based-on-transformer-models-4490316a1d80

Slide Share: https://www.slideshare.net/RaghavaUrs/videolanguage-pretraining-based-on-transformer-models

Video: 

Survey Paper: [Transformer based Video-Language Pre-training](https://arxiv.org/pdf/2109.09920.pdf)

References:

- Ruan, Ludan and Qin Jin. “Survey: Transformer based Video-Language Pre-training.” ArXiv abs/2109.09920 (2021): n. pag.
- Li, Linjie, et al. “Hero: Hierarchical Encoder for Video+Language Omni-Representation Pre-Training.” Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, https://doi.org/10.18653/v1/2020.emnlp-main.161.
- Tang, Yansong & Ding, Dajun & Rao, Yongming & Zheng, Yu & Zhang, Danyang & Zhao, Lili & Lu, Jiwen & Zhou, Jie. (2019). COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis. 1207–1216. 10.1109/CVPR.2019.00130.
