{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Weak_Supervision_Snorkel.ipynb","provenance":[],"authorship_tag":"ABX9TyM1X/akXXfSJbO+H7Rb3BFP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qbGRIffulU4k"},"source":["## Recommender Systems using Snorkel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alpNac4SopCe","executionInfo":{"status":"ok","timestamp":1637634716065,"user_tz":480,"elapsed":3404,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"7176ae0e-6213-4b86-98b0-01d6d0c676b2"},"source":["pip install snorkel"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: snorkel in /usr/local/lib/python3.7/dist-packages (0.9.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (4.62.3)\n","Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.4.1)\n","Requirement already satisfied: numpy<1.20.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.19.5)\n","Requirement already satisfied: tensorboard<2.7.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.6.0)\n","Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.5)\n","Requirement already satisfied: networkx<2.7,>=2.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (2.6.3)\n","Requirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from snorkel) (0.24.2)\n","Requirement already satisfied: munkres>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.1.4)\n","Requirement already satisfied: torch<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from snorkel) (1.10.0+cu111)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.0.0->snorkel) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<2.0.0,>=1.0.0->snorkel) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->snorkel) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (0.37.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (57.4.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (2.23.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (1.42.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (0.6.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7.0,>=2.0.0->snorkel) (3.17.3)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7.0,>=2.0.0->snorkel) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7.0,>=2.0.0->snorkel) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7.0,>=2.0.0->snorkel) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7.0,>=2.0.0->snorkel) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.7.0,>=2.0.0->snorkel) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7.0,>=2.0.0->snorkel) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7.0,>=2.0.0->snorkel) (3.10.0.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7.0,>=2.0.0->snorkel) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7.0,>=2.0.0->snorkel) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7.0,>=2.0.0->snorkel) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7.0,>=2.0.0->snorkel) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.7.0,>=2.0.0->snorkel) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7.0,>=2.0.0->snorkel) (3.1.1)\n"]}]},{"cell_type":"code","metadata":{"id":"z_Ii0dVblI1n","executionInfo":{"status":"ok","timestamp":1637634716066,"user_tz":480,"elapsed":5,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["import logging\n","import os\n","\n","logging.basicConfig(level=logging.INFO)\n","\n","\n","if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n","    os.chdir(\"recsys\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_q40RWEl4ml","executionInfo":{"status":"ok","timestamp":1637634719941,"user_tz":480,"elapsed":3879,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["import calendar\n","import gzip\n","import json\n","import logging\n","import os\n","import pickle\n","from datetime import datetime\n","from typing import Any, Dict, List, Optional, Tuple\n","\n","import gdown\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import backend as K\n","\n","IS_TEST = os.environ.get(\"TRAVIS\") == \"true\" or os.environ.get(\"IS_TEST\") == \"true\"\n","\n","YA_BOOKS_URL = \"https://drive.google.com/uc?id=1gH7dG4yQzZykTpbHYsrw2nFknjUm0Mol\"\n","YA_INTERACTIONS_URL = \"https://drive.google.com/uc?id=1NNX7SWcKahezLFNyiW88QFPAqOAYP5qg\"\n","YA_REVIEWS_URL = \"https://drive.google.com/uc?id=1M5iqCZ8a7rZRtsmY5KQ5rYnP9S0bQJVo\"\n","SMALL_DATA_URL = \"https://drive.google.com/uc?id=1_UY4xTbk3o0xjGbVllQZC2bBt-WAwyF_\"\n","\n","BOOK_DATA = \"data/goodreads_books_young_adult.json.gz\"\n","INTERACTIONS_DATA = \"data/goodreads_interactions_young_adult.json.gz\"\n","REVIEWS_DATA = \"data/goodreads_reviews_young_adult.json.gz\"\n","SAMPLE_DATA = \"data/sample_data.pkl\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3Qh1iLNlyv0","executionInfo":{"status":"ok","timestamp":1637634719942,"user_tz":480,"elapsed":16,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["def download_and_process_data() -> Tuple[Tuple[pd.DataFrame, ...], pd.DataFrame]:\n","    logging.info(\"Downloading raw data\")\n","    maybe_download_files()\n","    if IS_TEST:\n","        return load_small_sample()\n","    logging.info(\"Processing book data\")\n","    df_books, book_id_to_idx = process_books_data()\n","    logging.info(\"Processing interaction data\")\n","    df_interactions, user_id_to_idx = process_interactions_data(book_id_to_idx)\n","    df_interactions_nz = df_interactions[df_interactions.rating != 0]\n","    ratings_map = {1: 0, 2: 0, 3: 0, 4: 1, 5: 1}\n","    df_interactions_nz[\"rating_4_5\"] = df_interactions_nz.rating.map(ratings_map)\n","    logging.info(\"Processing review data\")\n","    df_reviews = process_reviews_data(book_id_to_idx, user_id_to_idx)\n","    logging.info(\"Joining interaction data\")\n","    # Compute book_idxs for each user.\n","    user_to_books = (\n","        df_interactions.groupby(\"user_idx\")[\"book_idx\"]\n","        .apply(tuple)\n","        .reset_index()\n","        .rename(columns={\"book_idx\": \"book_idxs\"})\n","    )\n","    data = user_to_books.merge(df_interactions_nz, on=\"user_idx\", how=\"inner\")[\n","        [\"user_idx\", \"book_idxs\", \"book_idx\", \"rating_4_5\"]\n","    ].merge(\n","        df_reviews[[\"user_idx\", \"book_idx\", \"review_text\"]],\n","        on=[\"user_idx\", \"book_idx\"],\n","        how=\"left\",\n","    )\n","    data = data.rename(columns={\"rating_4_5\": \"rating\"})\n","    user_idxs = list(user_id_to_idx.values())\n","    return split_data(user_idxs, data), df_books"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qj4EgWkZmEQG","executionInfo":{"status":"ok","timestamp":1637634719942,"user_tz":480,"elapsed":15,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["def maybe_download_files(data_dir: str = \"data\") -> None:\n","    if not os.path.exists(data_dir):\n","        os.makedirs(data_dir, exist_ok=True)\n","        if IS_TEST:\n","            # Sample data pickle\n","            gdown.download(SMALL_DATA_URL, output=SAMPLE_DATA, quiet=None)\n","        else:\n","            # Books\n","            gdown.download(YA_BOOKS_URL, output=BOOK_DATA, quiet=None)\n","            # Interactions\n","            gdown.download(YA_INTERACTIONS_URL, output=INTERACTIONS_DATA, quiet=None)\n","            # Reviews\n","            gdown.download(YA_REVIEWS_URL, output=REVIEWS_DATA, quiet=None)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3oeb0vTmlvd","executionInfo":{"status":"ok","timestamp":1637634719943,"user_tz":480,"elapsed":15,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["def process_books_data(\n","    book_path: str = BOOK_DATA, min_ratings: int = 100, max_ratings: int = 15000\n",") -> Tuple[pd.DataFrame, Dict[int, int]]:\n","    books = load_data(book_path, None)\n","    df_books = pd.DataFrame(books)\n","    df_books = df_books[\n","        [\n","            \"authors\",\n","            \"average_rating\",\n","            \"book_id\",\n","            \"country_code\",\n","            \"description\",\n","            \"is_ebook\",\n","            \"language_code\",\n","            \"ratings_count\",\n","            \"similar_books\",\n","            \"text_reviews_count\",\n","            \"title\",\n","        ]\n","    ]\n","    df_books = df_books.astype(\n","        dict(\n","            average_rating=float,\n","            book_id=int,\n","            is_ebook=bool,\n","            ratings_count=int,\n","            text_reviews_count=int,\n","        )\n","    )\n","    # Turns author role dict into list of <= 5 authors for simplicity.\n","    df_books.authors = df_books.authors.map(\n","        lambda l: [pair[\"author_id\"] for pair in l[:5]]\n","    )\n","    df_books[\"first_author\"] = df_books.authors.map(lambda l: int(l[0]))\n","\n","    df_books = df_books[\n","        (df_books.ratings_count >= min_ratings)\n","        & (df_books.ratings_count <= max_ratings)\n","    ]\n","\n","    book_id_to_idx = {v: i for i, v in enumerate(df_books.book_id)}\n","    df_books[\"book_idx\"] = df_books.book_id.map(book_id_to_idx)\n","    return df_books, book_id_to_idx\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dVzc9umImq_M","executionInfo":{"status":"ok","timestamp":1637634719944,"user_tz":480,"elapsed":15,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["def process_interactions_data(\n","    book_id_to_idx: Dict[int, int],\n","    interactions_path: str = INTERACTIONS_DATA,\n","    min_user_count: int = 25,\n","    max_user_count: int = 200,\n","    max_to_load: int = 5_000_000,\n",") -> Tuple[pd.DataFrame, Dict[int, int]]:\n","    interactions = load_data(\n","        interactions_path,\n","        max_to_load,\n","        dict(book_id=set(map(str, book_id_to_idx.keys()))),\n","    )\n","    df_interactions = pd.DataFrame(interactions)\n","    df_interactions = df_interactions[\n","        [\"book_id\", \"is_read\", \"rating\", \"review_id\", \"user_id\"]\n","    ]\n","    df_interactions = df_interactions.astype(\n","        dict(book_id=int, is_read=bool, rating=int)\n","    )\n","    df_interactions[\"book_idx\"] = df_interactions.book_id.map(book_id_to_idx)\n","    user_counts = df_interactions.groupby([\"user_id\"]).size()\n","    user_mask = (user_counts >= min_user_count) & (user_counts <= max_user_count)\n","    users_filt = user_counts[user_mask].index\n","    user_id_to_idx = {v: i for i, v in enumerate(users_filt)}\n","    df_interactions = df_interactions[\n","        df_interactions.user_id.isin(set(user_id_to_idx.keys()))\n","    ]\n","    df_interactions[\"user_idx\"] = df_interactions.user_id.map(user_id_to_idx)\n","    return df_interactions, user_id_to_idx\n","\n","\n","def process_reviews_data(\n","    book_id_to_idx: Dict[int, int],\n","    user_id_to_idx: Dict[int, int],\n","    reviews_path: str = REVIEWS_DATA,\n",") -> pd.DataFrame:\n","    reviews = load_data(\n","        reviews_path,\n","        None,\n","        dict(\n","            book_id=set(map(str, book_id_to_idx.keys())),\n","            user_id=set(user_id_to_idx.keys()),\n","        ),\n","    )\n","    df_reviews = pd.DataFrame(reviews)\n","    df_reviews[\"book_idx\"] = df_reviews.book_id.astype(\"int\").map(book_id_to_idx)\n","    df_reviews[\"user_idx\"] = df_reviews.user_id.map(user_id_to_idx)\n","    return df_reviews\n","\n","\n","def split_data(user_idxs, data: pd.DataFrame) -> Tuple[pd.DataFrame, ...]:\n","    user_idxs_train, user_idxs_test = train_test_split(user_idxs, test_size=0.05)\n","    user_idxs_train, user_idxs_dev = train_test_split(user_idxs_train, test_size=0.01)\n","    user_idxs_train, user_idxs_val = train_test_split(user_idxs_train, test_size=0.01)\n","\n","    data_train = data[data.user_idx.isin(set(user_idxs_train))].drop(\"rating\", axis=1)\n","    data_test = data[data.user_idx.isin(set(user_idxs_test))]\n","    data_dev = data[data.user_idx.isin(set(user_idxs_dev))]\n","    data_val = data[data.user_idx.isin(set(user_idxs_val))]\n","    return data_train, data_test, data_dev, data_val"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"FA4vhwBjmvST","executionInfo":{"status":"ok","timestamp":1637634720184,"user_tz":480,"elapsed":255,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["def recall_batch(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    true_positives = K.sum(K.round(y_true * y_pred))\n","    all_positives = K.sum(y_true)\n","    return true_positives / (all_positives + K.epsilon())\n","\n","\n","def precision_batch(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    true_positives = K.sum(K.round(y_true * y_pred))\n","    predicted_positives = K.sum(K.round(y_pred))\n","    return true_positives / (predicted_positives + K.epsilon())\n","\n","\n","def f1_batch(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    prec = precision_batch(y_true, y_pred)\n","    rec = recall_batch(y_true, y_pred)\n","    return 2 * ((prec * rec) / (prec + rec + K.epsilon()))\n","\n","\n","def get_n_epochs() -> int:\n","    return 2 if IS_TEST else 30"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3MhTdztm5_X","executionInfo":{"status":"ok","timestamp":1637634720185,"user_tz":480,"elapsed":5,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["# +\n","def save_small_sample():\n","    \"\"\"Load full data, sample, and dump to file..\"\"\"\n","    (df_train, df_test, df_dev, df_valid), df_books = download_and_process_data()\n","    df_train = df_train.dropna().sample(frac=0.01)\n","    df_test = df_test.dropna().sample(frac=0.01)\n","    df_dev = df_dev.dropna().sample(frac=0.01)\n","    df_valid = df_valid.dropna().sample(frac=0.01)\n","    df_all = pd.concat([df_train, df_test, df_dev, df_valid], axis=0)\n","    df_books = df_books.merge(\n","        df_all[[\"book_idx\"]].drop_duplicates(), on=\"book_idx\", how=\"inner\"\n","    )\n","    with open(SAMPLE_DATA, \"wb\") as f:\n","        pickle.dump(df_train, f)\n","        pickle.dump(df_test, f)\n","        pickle.dump(df_dev, f)\n","        pickle.dump(df_valid, f)\n","        pickle.dump(df_books, f)\n","\n","\n","def load_small_sample():\n","    \"\"\"Load sample data.\"\"\"\n","    with open(SAMPLE_DATA, \"rb\") as f:\n","        df_train = pickle.load(f)\n","        df_test = pickle.load(f)\n","        df_dev = pickle.load(f)\n","        df_valid = pickle.load(f)\n","        df_books = pickle.load(f)\n","        return (df_train, df_test, df_dev, df_valid), df_books\n","\n","\n","# -\n","\n","\n","def maybe_download_files(data_dir: str = \"data\") -> None:\n","    if not os.path.exists(data_dir):\n","        os.makedirs(data_dir, exist_ok=True)\n","        if IS_TEST:\n","            # Sample data pickle\n","            gdown.download(SMALL_DATA_URL, output=SAMPLE_DATA, quiet=None)\n","        else:\n","            # Books\n","            gdown.download(YA_BOOKS_URL, output=BOOK_DATA, quiet=None)\n","            # Interactions\n","            gdown.download(YA_INTERACTIONS_URL, output=INTERACTIONS_DATA, quiet=None)\n","            # Reviews\n","            gdown.download(YA_REVIEWS_URL, output=REVIEWS_DATA, quiet=None)\n","\n","\n","def get_timestamp(date_str: str) -> datetime.timestamp:\n","    month_to_int = dict((v, k) for k, v in enumerate(calendar.month_abbr))\n","    _, month, day, _, _, year = date_str.split()\n","    dt = datetime(year=int(year), month=month_to_int[month], day=int(day))\n","    return datetime.timestamp(dt)\n","\n","\n","def load_data(\n","    file_name: str, max_to_load: int = 100, filter_dict: Optional[dict] = None\n",") -> List[Dict[str, Any]]:\n","    count = 0\n","    data = []\n","    filter_dict = filter_dict or {}\n","    with gzip.open(file_name) as fin:\n","        for l in fin:\n","            d = json.loads(l)\n","            for k, v in filter_dict.items():\n","                if d[k] not in v:\n","                    break\n","            else:\n","                count += 1\n","                data.append(d)\n","                if (max_to_load is not None) and (count >= max_to_load):\n","                    break\n","    return data\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"B_LW9ofRlcMh","executionInfo":{"status":"ok","timestamp":1637634944408,"user_tz":480,"elapsed":224227,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"db56170f-a13d-4aa8-a29d-a62e3126a9a9"},"source":["#from utils import download_and_process_data\n","\n","(df_train, df_test, df_dev, df_valid), df_books = download_and_process_data()\n","\n","df_books.head()"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:Downloading raw data\n","INFO:root:Processing book data\n","INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n","INFO:root:Processing interaction data\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if sys.path[0] == '':\n","INFO:root:Processing review data\n","INFO:root:Joining interaction data\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>authors</th>\n","      <th>average_rating</th>\n","      <th>book_id</th>\n","      <th>country_code</th>\n","      <th>description</th>\n","      <th>is_ebook</th>\n","      <th>language_code</th>\n","      <th>ratings_count</th>\n","      <th>similar_books</th>\n","      <th>text_reviews_count</th>\n","      <th>title</th>\n","      <th>first_author</th>\n","      <th>book_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>[293603]</td>\n","      <td>4.35</td>\n","      <td>10099492</td>\n","      <td>US</td>\n","      <td>It all comes down to this.\\nVlad's running out...</td>\n","      <td>True</td>\n","      <td>eng</td>\n","      <td>152</td>\n","      <td>[25861113, 7430195, 18765937, 6120544, 3247550...</td>\n","      <td>9</td>\n","      <td>Twelfth Grade Kills (The Chronicles of Vladimi...</td>\n","      <td>293603</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[4018722]</td>\n","      <td>3.71</td>\n","      <td>22642971</td>\n","      <td>US</td>\n","      <td>The future world is at peace.\\nElla Shepherd h...</td>\n","      <td>True</td>\n","      <td>eng</td>\n","      <td>1525</td>\n","      <td>[20499652, 17934493, 13518102, 16210411, 17149...</td>\n","      <td>428</td>\n","      <td>The Body Electric</td>\n","      <td>4018722</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[6537142]</td>\n","      <td>3.89</td>\n","      <td>31556136</td>\n","      <td>US</td>\n","      <td>A gorgeously written and deeply felt literary ...</td>\n","      <td>True</td>\n","      <td></td>\n","      <td>109</td>\n","      <td>[]</td>\n","      <td>45</td>\n","      <td>Like Water</td>\n","      <td>6537142</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>[6455200, 5227552]</td>\n","      <td>3.90</td>\n","      <td>18522274</td>\n","      <td>US</td>\n","      <td>Zoe Vanderveen is on the run with her captor t...</td>\n","      <td>True</td>\n","      <td>en-US</td>\n","      <td>191</td>\n","      <td>[25063023, 18553080, 17567752, 18126509, 17997...</td>\n","      <td>6</td>\n","      <td>Volition (The Perception Trilogy, #2)</td>\n","      <td>6455200</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>[187837]</td>\n","      <td>3.19</td>\n","      <td>17262776</td>\n","      <td>US</td>\n","      <td>The war is over, but for thirteen-year-old Rac...</td>\n","      <td>True</td>\n","      <td>eng</td>\n","      <td>248</td>\n","      <td>[16153997, 10836616, 17262238, 16074827, 13628...</td>\n","      <td>68</td>\n","      <td>Little Red Lies</td>\n","      <td>187837</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               authors  average_rating  ...  first_author book_idx\n","3             [293603]            4.35  ...        293603        0\n","4            [4018722]            3.71  ...       4018722        1\n","5            [6537142]            3.89  ...       6537142        2\n","12  [6455200, 5227552]            3.90  ...       6455200        3\n","13            [187837]            3.19  ...        187837        4\n","\n","[5 rows x 13 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"96cQJOfOlfYl","executionInfo":{"status":"ok","timestamp":1637634944409,"user_tz":480,"elapsed":9,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"ebe66218-8fe7-42f9-d252-bc2c8383b602"},"source":["df_dev.sample(frac=1, random_state=12).head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_idx</th>\n","      <th>book_idxs</th>\n","      <th>book_idx</th>\n","      <th>rating</th>\n","      <th>review_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>567397</th>\n","      <td>21906</td>\n","      <td>(25315, 10119, 8253, 6133, 13572, 13579, 8966,...</td>\n","      <td>24514</td>\n","      <td>1</td>\n","      <td>'La lluvia en tu habitacion' no es una novela ...</td>\n","    </tr>\n","    <tr>\n","      <th>449015</th>\n","      <td>17311</td>\n","      <td>(21132, 19986, 2462, 6268, 14212, 5607, 7524, ...</td>\n","      <td>7524</td>\n","      <td>1</td>\n","      <td>I loved this. Sweet little short story about a...</td>\n","    </tr>\n","    <tr>\n","      <th>427620</th>\n","      <td>16470</td>\n","      <td>(18839, 10934, 23247, 6363, 31045, 25682, 2457...</td>\n","      <td>9849</td>\n","      <td>0</td>\n","      <td>I think this book can be summed up by the foll...</td>\n","    </tr>\n","    <tr>\n","      <th>322779</th>\n","      <td>12455</td>\n","      <td>(6401, 3276, 10432, 24284, 4285, 24352, 16476,...</td>\n","      <td>4285</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>411652</th>\n","      <td>15883</td>\n","      <td>(30888, 20262, 17830, 30416, 12880, 1828, 7907...</td>\n","      <td>8755</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        user_idx  ...                                        review_text\n","567397     21906  ...  'La lluvia en tu habitacion' no es una novela ...\n","449015     17311  ...  I loved this. Sweet little short story about a...\n","427620     16470  ...  I think this book can be summed up by the foll...\n","322779     12455  ...                                                NaN\n","411652     15883  ...                                                NaN\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"MX52ujPamd8O","executionInfo":{"status":"ok","timestamp":1637634944410,"user_tz":480,"elapsed":8,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["POSITIVE = 1\n","NEGATIVE = 0\n","ABSTAIN = -1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqQhwD9zoSw7","executionInfo":{"status":"ok","timestamp":1637634944410,"user_tz":480,"elapsed":7,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["from snorkel.labeling.lf import labeling_function"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nj4ZzXUmevA","executionInfo":{"status":"ok","timestamp":1637634944627,"user_tz":480,"elapsed":224,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["from snorkel.labeling.lf import labeling_function\n","\n","book_to_first_author = dict(zip(df_books.book_idx, df_books.first_author))\n","first_author_to_books_df = df_books.groupby(\"first_author\")[[\"book_idx\"]].agg(set)\n","first_author_to_books = dict(\n","    zip(first_author_to_books_df.index, first_author_to_books_df.book_idx)\n",")\n","\n","\n","@labeling_function(\n","    resources=dict(\n","        book_to_first_author=book_to_first_author,\n","        first_author_to_books=first_author_to_books,\n","    )\n",")\n","def shared_first_author(x, book_to_first_author, first_author_to_books):\n","    author = book_to_first_author[x.book_idx]\n","    same_author_books = first_author_to_books[author]\n","    num_read = len(set(x.book_idxs).intersection(same_author_books))\n","    return POSITIVE if num_read > 15 else ABSTAIN"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eTDKsoBnGi2","executionInfo":{"status":"ok","timestamp":1637634944627,"user_tz":480,"elapsed":2,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["low_rating_strs = [\n","    \"one star\",\n","    \"1 star\",\n","    \"two star\",\n","    \"2 star\",\n","    \"3 star\",\n","    \"three star\",\n","    \"3.5 star\",\n","    \"2.5 star\",\n","    \"1 out of 5\",\n","    \"2 out of 5\",\n","    \"3 out of 5\",\n","]\n","high_rating_strs = [\"5 stars\", \"five stars\", \"four stars\", \"4 stars\", \"4.5 stars\"]\n","\n","\n","@labeling_function(\n","    resources=dict(low_rating_strs=low_rating_strs, high_rating_strs=high_rating_strs)\n",")\n","def stars_in_review(x, low_rating_strs, high_rating_strs):\n","    if not isinstance(x.review_text, str):\n","        return ABSTAIN\n","    for low_rating_str in low_rating_strs:\n","        if low_rating_str in x.review_text.lower():\n","            return NEGATIVE\n","    for high_rating_str in high_rating_strs:\n","        if high_rating_str in x.review_text.lower():\n","            return POSITIVE\n","    return ABSTAIN"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCHTTEaAnJLd","executionInfo":{"status":"ok","timestamp":1637634945145,"user_tz":480,"elapsed":520,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["from snorkel.preprocess import preprocessor\n","from textblob import TextBlob\n","\n","\n","@preprocessor(memoize=True)\n","def textblob_polarity(x):\n","    if isinstance(x.review_text, str):\n","        x.blob = TextBlob(x.review_text)\n","    else:\n","        x.blob = None\n","    return x\n","\n","\n","# Label high polarity reviews as positive.\n","@labeling_function(pre=[textblob_polarity])\n","def polarity_positive(x):\n","    if x.blob:\n","        if x.blob.polarity > 0.3:\n","            return POSITIVE\n","    return ABSTAIN\n","\n","\n","# Label high subjectivity reviews as positive.\n","@labeling_function(pre=[textblob_polarity])\n","def subjectivity_positive(x):\n","    if x.blob:\n","        if x.blob.subjectivity > 0.75:\n","            return POSITIVE\n","    return ABSTAIN\n","\n","\n","# Label low polarity reviews as negative.\n","@labeling_function(pre=[textblob_polarity])\n","def polarity_negative(x):\n","    if x.blob:\n","        if x.blob.polarity < 0.0:\n","            return NEGATIVE\n","    return ABSTAIN"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2jv01tYnLp7","executionInfo":{"status":"ok","timestamp":1637634953930,"user_tz":480,"elapsed":8789,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"2fcc21c0-3ec0-4f18-acaf-0d102d6bcef9"},"source":["from snorkel.labeling import PandasLFApplier, LFAnalysis\n","\n","lfs = [\n","    stars_in_review,\n","    shared_first_author,\n","    polarity_positive,\n","    subjectivity_positive,\n","    polarity_negative,\n","]\n","\n","applier = PandasLFApplier(lfs)\n","L_dev = applier.apply(df_dev)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8141/8141 [00:08<00:00, 925.71it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"zjJNh2zmnNkg","executionInfo":{"status":"ok","timestamp":1637634954136,"user_tz":480,"elapsed":219,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"7613ebad-2931-4bb1-df83-8e17b7d56746"},"source":["LFAnalysis(L_dev, lfs).lf_summary(df_dev.rating.values)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n","  \"will result in an error\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n","  \"will result in an error\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n","  \"will result in an error\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n","  \"will result in an error\", FutureWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n","  \"will result in an error\", FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>j</th>\n","      <th>Polarity</th>\n","      <th>Coverage</th>\n","      <th>Overlaps</th>\n","      <th>Conflicts</th>\n","      <th>Correct</th>\n","      <th>Incorrect</th>\n","      <th>Emp. Acc.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>stars_in_review</th>\n","      <td>0</td>\n","      <td>[0, 1]</td>\n","      <td>0.019285</td>\n","      <td>0.005528</td>\n","      <td>0.002457</td>\n","      <td>132</td>\n","      <td>25</td>\n","      <td>0.840764</td>\n","    </tr>\n","    <tr>\n","      <th>shared_first_author</th>\n","      <td>1</td>\n","      <td>[1]</td>\n","      <td>0.068296</td>\n","      <td>0.003071</td>\n","      <td>0.001351</td>\n","      <td>356</td>\n","      <td>200</td>\n","      <td>0.640288</td>\n","    </tr>\n","    <tr>\n","      <th>polarity_positive</th>\n","      <td>2</td>\n","      <td>[1]</td>\n","      <td>0.047169</td>\n","      <td>0.015600</td>\n","      <td>0.001106</td>\n","      <td>301</td>\n","      <td>83</td>\n","      <td>0.783854</td>\n","    </tr>\n","    <tr>\n","      <th>subjectivity_positive</th>\n","      <td>3</td>\n","      <td>[1]</td>\n","      <td>0.016828</td>\n","      <td>0.012161</td>\n","      <td>0.001720</td>\n","      <td>103</td>\n","      <td>34</td>\n","      <td>0.751825</td>\n","    </tr>\n","    <tr>\n","      <th>polarity_negative</th>\n","      <td>4</td>\n","      <td>[0]</td>\n","      <td>0.015477</td>\n","      <td>0.002702</td>\n","      <td>0.002457</td>\n","      <td>65</td>\n","      <td>61</td>\n","      <td>0.515873</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n","stars_in_review        0   [0, 1]  0.019285  ...      132         25   0.840764\n","shared_first_author    1      [1]  0.068296  ...      356        200   0.640288\n","polarity_positive      2      [1]  0.047169  ...      301         83   0.783854\n","subjectivity_positive  3      [1]  0.016828  ...      103         34   0.751825\n","polarity_negative      4      [0]  0.015477  ...       65         61   0.515873\n","\n","[5 rows x 8 columns]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqjvIpf_nP6c","executionInfo":{"status":"ok","timestamp":1637635860274,"user_tz":480,"elapsed":906141,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"35f4463c-10c2-45fc-b7b1-c72c3a5f623f"},"source":["from snorkel.labeling.model import LabelModel\n","\n","L_train = applier.apply(df_train)\n","label_model = LabelModel(cardinality=2, verbose=True)\n","label_model.fit(L_train, n_epochs=5000, seed=123, log_freq=20, lr=0.01)\n","preds_train = label_model.predict(L_train)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 797253/797253 [14:44<00:00, 901.07it/s]\n","INFO:root:Computing O...\n","INFO:root:Estimating \\mu...\n","  0%|          | 0/5000 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.002]\n","  0%|          | 1/5000 [00:00<11:49,  7.05epoch/s]INFO:root:[20 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[40 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[60 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[80 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n","  2%|▏         | 105/5000 [00:00<00:09, 523.86epoch/s]INFO:root:[120 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[140 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[160 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[180 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n","  4%|▍         | 217/5000 [00:00<00:06, 771.35epoch/s]INFO:root:[220 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[240 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[260 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[280 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n","  6%|▌         | 312/5000 [00:00<00:05, 836.79epoch/s]INFO:root:[320 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[340 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[360 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[380 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n","  8%|▊         | 403/5000 [00:00<00:05, 859.93epoch/s]INFO:root:[420 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[440 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[460 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[480 epochs]: TRAIN:[loss=0.000]\n"," 10%|▉         | 493/5000 [00:00<00:05, 838.38epoch/s]INFO:root:[500 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[520 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[540 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[560 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[580 epochs]: TRAIN:[loss=0.000]\n"," 12%|█▏        | 591/5000 [00:00<00:05, 881.26epoch/s]INFO:root:[600 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[620 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[640 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[660 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[680 epochs]: TRAIN:[loss=0.000]\n"," 14%|█▎        | 687/5000 [00:00<00:04, 903.70epoch/s]INFO:root:[700 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[720 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[740 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[760 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[780 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[800 epochs]: TRAIN:[loss=0.000]\n"," 16%|█▌        | 801/5000 [00:00<00:04, 975.61epoch/s]INFO:root:[820 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[840 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[860 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[880 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[900 epochs]: TRAIN:[loss=0.000]\n"," 18%|█▊        | 906/5000 [00:01<00:04, 997.22epoch/s]INFO:root:[920 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[940 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[960 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[980 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1000 epochs]: TRAIN:[loss=0.000]\n"," 20%|██        | 1020/5000 [00:01<00:03, 1039.94epoch/s]INFO:root:[1020 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1040 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1060 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1080 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1100 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1120 epochs]: TRAIN:[loss=0.000]\n"," 22%|██▎       | 1125/5000 [00:01<00:03, 1019.06epoch/s]INFO:root:[1140 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1160 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1180 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1200 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1220 epochs]: TRAIN:[loss=0.000]\n"," 25%|██▍       | 1228/5000 [00:01<00:03, 986.94epoch/s] INFO:root:[1240 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1260 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1280 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1300 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1320 epochs]: TRAIN:[loss=0.000]\n"," 27%|██▋       | 1328/5000 [00:01<00:03, 934.50epoch/s]INFO:root:[1340 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1360 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1380 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1400 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1420 epochs]: TRAIN:[loss=0.000]\n"," 28%|██▊       | 1423/5000 [00:01<00:03, 935.49epoch/s]INFO:root:[1440 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1460 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1480 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1500 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1520 epochs]: TRAIN:[loss=0.000]\n"," 30%|███       | 1525/5000 [00:01<00:03, 955.32epoch/s]INFO:root:[1540 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1560 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1580 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1600 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1620 epochs]: TRAIN:[loss=0.000]\n"," 32%|███▏      | 1622/5000 [00:01<00:03, 956.12epoch/s]INFO:root:[1640 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1660 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1680 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1700 epochs]: TRAIN:[loss=0.000]\n"," 34%|███▍      | 1718/5000 [00:01<00:03, 949.72epoch/s]INFO:root:[1720 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1740 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1760 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1780 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1800 epochs]: TRAIN:[loss=0.000]\n"," 36%|███▋      | 1818/5000 [00:02<00:03, 963.34epoch/s]INFO:root:[1820 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1840 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1860 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1880 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1900 epochs]: TRAIN:[loss=0.000]\n"," 38%|███▊      | 1915/5000 [00:02<00:03, 964.45epoch/s]INFO:root:[1920 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1940 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1960 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[1980 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2000 epochs]: TRAIN:[loss=0.000]\n"," 40%|████      | 2012/5000 [00:02<00:03, 963.59epoch/s]INFO:root:[2020 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2040 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2060 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2080 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2100 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2120 epochs]: TRAIN:[loss=0.000]\n"," 42%|████▏     | 2121/5000 [00:02<00:02, 996.76epoch/s]INFO:root:[2140 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2160 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2180 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2200 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2220 epochs]: TRAIN:[loss=0.000]\n"," 44%|████▍     | 2221/5000 [00:02<00:02, 989.44epoch/s]INFO:root:[2240 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2260 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2280 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2300 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2320 epochs]: TRAIN:[loss=0.000]\n"," 47%|████▋     | 2326/5000 [00:02<00:02, 1006.00epoch/s]INFO:root:[2340 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2360 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2380 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2400 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2420 epochs]: TRAIN:[loss=0.000]\n"," 49%|████▊     | 2428/5000 [00:02<00:02, 1009.02epoch/s]INFO:root:[2440 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2460 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2480 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2500 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2520 epochs]: TRAIN:[loss=0.000]\n"," 51%|█████     | 2529/5000 [00:02<00:02, 988.23epoch/s] INFO:root:[2540 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2560 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2580 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2600 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2620 epochs]: TRAIN:[loss=0.000]\n"," 53%|█████▎    | 2628/5000 [00:02<00:02, 974.84epoch/s]INFO:root:[2640 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2660 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2680 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2700 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2720 epochs]: TRAIN:[loss=0.000]\n"," 55%|█████▍    | 2726/5000 [00:02<00:02, 959.02epoch/s]INFO:root:[2740 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2760 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2780 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2800 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2820 epochs]: TRAIN:[loss=0.000]\n"," 57%|█████▋    | 2830/5000 [00:03<00:02, 979.89epoch/s]INFO:root:[2840 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2860 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2880 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2900 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2920 epochs]: TRAIN:[loss=0.000]\n"," 59%|█████▉    | 2938/5000 [00:03<00:02, 1008.83epoch/s]INFO:root:[2940 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2960 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[2980 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3000 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3020 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3040 epochs]: TRAIN:[loss=0.000]\n"," 61%|██████    | 3042/5000 [00:03<00:01, 1014.59epoch/s]INFO:root:[3060 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3080 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3100 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3120 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3140 epochs]: TRAIN:[loss=0.000]\n"," 63%|██████▎   | 3149/5000 [00:03<00:01, 1030.68epoch/s]INFO:root:[3160 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3180 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3200 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3220 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3240 epochs]: TRAIN:[loss=0.000]\n"," 65%|██████▌   | 3253/5000 [00:03<00:01, 1010.96epoch/s]INFO:root:[3260 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3280 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3300 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3320 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3340 epochs]: TRAIN:[loss=0.000]\n"," 67%|██████▋   | 3355/5000 [00:03<00:01, 982.90epoch/s] INFO:root:[3360 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3380 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3400 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3420 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3440 epochs]: TRAIN:[loss=0.000]\n"," 69%|██████▉   | 3454/5000 [00:03<00:01, 929.17epoch/s]INFO:root:[3460 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3480 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3500 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3520 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3540 epochs]: TRAIN:[loss=0.000]\n"," 71%|███████   | 3548/5000 [00:03<00:01, 928.40epoch/s]INFO:root:[3560 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3580 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3600 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3620 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3640 epochs]: TRAIN:[loss=0.000]\n"," 73%|███████▎  | 3642/5000 [00:03<00:01, 928.37epoch/s]INFO:root:[3660 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3680 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3700 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3720 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3740 epochs]: TRAIN:[loss=0.000]\n"," 75%|███████▍  | 3743/5000 [00:03<00:01, 949.69epoch/s]INFO:root:[3760 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3780 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3800 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3820 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3840 epochs]: TRAIN:[loss=0.000]\n"," 77%|███████▋  | 3843/5000 [00:04<00:01, 960.85epoch/s]INFO:root:[3860 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3880 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3900 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3920 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3940 epochs]: TRAIN:[loss=0.000]\n"," 79%|███████▉  | 3951/5000 [00:04<00:01, 993.78epoch/s]INFO:root:[3960 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[3980 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4000 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4020 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4040 epochs]: TRAIN:[loss=0.000]\n"," 81%|████████  | 4055/5000 [00:04<00:00, 1005.97epoch/s]INFO:root:[4060 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4080 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4100 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4120 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4140 epochs]: TRAIN:[loss=0.000]\n"," 83%|████████▎ | 4156/5000 [00:04<00:00, 1003.53epoch/s]INFO:root:[4160 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4180 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4200 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4220 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4240 epochs]: TRAIN:[loss=0.000]\n"," 85%|████████▌ | 4257/5000 [00:04<00:00, 995.63epoch/s] INFO:root:[4260 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4280 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4300 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4320 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4340 epochs]: TRAIN:[loss=0.000]\n"," 87%|████████▋ | 4357/5000 [00:04<00:00, 990.06epoch/s]INFO:root:[4360 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4380 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4400 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4420 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4440 epochs]: TRAIN:[loss=0.000]\n"," 89%|████████▉ | 4457/5000 [00:04<00:00, 961.61epoch/s]INFO:root:[4460 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4480 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4500 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4520 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4540 epochs]: TRAIN:[loss=0.000]\n"," 91%|█████████ | 4554/5000 [00:04<00:00, 960.48epoch/s]INFO:root:[4560 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4580 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4600 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4620 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4640 epochs]: TRAIN:[loss=0.000]\n"," 93%|█████████▎| 4651/5000 [00:04<00:00, 954.07epoch/s]INFO:root:[4660 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4680 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4700 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4720 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4740 epochs]: TRAIN:[loss=0.000]\n"," 95%|█████████▌| 4759/5000 [00:05<00:00, 989.17epoch/s]INFO:root:[4760 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4780 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4800 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4820 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4840 epochs]: TRAIN:[loss=0.000]\n"," 97%|█████████▋| 4859/5000 [00:05<00:00, 980.56epoch/s]INFO:root:[4860 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4880 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4900 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4920 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4940 epochs]: TRAIN:[loss=0.000]\n","INFO:root:[4960 epochs]: TRAIN:[loss=0.000]\n"," 99%|█████████▉| 4961/5000 [00:05<00:00, 991.97epoch/s]INFO:root:[4980 epochs]: TRAIN:[loss=0.000]\n","100%|██████████| 5000/5000 [00:05<00:00, 952.66epoch/s]\n","INFO:root:Finished Training\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d51hc-dnnSrh","executionInfo":{"status":"ok","timestamp":1637635860275,"user_tz":480,"elapsed":18,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"7b32153d-157d-4722-ec67-d1095250d5ba"},"source":["from snorkel.labeling import filter_unlabeled_dataframe\n","\n","df_train_filtered, preds_train_filtered = filter_unlabeled_dataframe(\n","    df_train, preds_train, L_train\n",")\n","df_train_filtered[\"rating\"] = preds_train_filtered"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","metadata":{"id":"J4hg_qdunUfT","executionInfo":{"status":"ok","timestamp":1637636084923,"user_tz":480,"elapsed":173,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["import numpy as np\n","import tensorflow as tf\n","#from utils import precision_batch, recall_batch, f1_batch\n","\n","n_books = max([max(df.book_idx) for df in [df_train, df_test, df_dev, df_valid]])\n","\n","\n","# Keras model to predict rating given book_idxs and book_idx.\n","def get_model(embed_dim=64, hidden_layer_sizes=[32]):\n","    # Compute embedding for book_idxs.\n","    len_book_idxs = tf.keras.layers.Input([])\n","    book_idxs = tf.keras.layers.Input([None])\n","    # book_idxs % n_books is to prevent crashing if a book_idx in book_idxs is > n_books.\n","    book_idxs_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idxs % n_books)\n","    book_idxs_emb = tf.math.divide(\n","        tf.keras.backend.sum(book_idxs_emb, axis=1), tf.expand_dims(len_book_idxs, 1)\n","    )\n","    # Compute embedding for book_idx.\n","    book_idx = tf.keras.layers.Input([])\n","    book_idx_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idx)\n","    input_layer = tf.keras.layers.concatenate([book_idxs_emb, book_idx_emb], 1)\n","    # Build Multi Layer Perceptron on input layer.\n","    cur_layer = input_layer\n","    for size in hidden_layer_sizes:\n","        tf.keras.layers.Dense(size, activation=tf.nn.relu)(cur_layer)\n","    output_layer = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(cur_layer)\n","    # Create and compile keras model.\n","    model = tf.keras.Model(\n","        inputs=[len_book_idxs, book_idxs, book_idx], outputs=[output_layer]\n","    )\n","    model.compile(\n","        \"Adagrad\",\n","        \"binary_crossentropy\",\n","        metrics=[\"accuracy\", f1_batch, precision_batch, recall_batch],\n","    )\n","    return model"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"by_xKihbnW78","executionInfo":{"status":"ok","timestamp":1637636097350,"user_tz":480,"elapsed":183,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}}},"source":["# Generator to turn dataframe into data points.\n","def get_data_points_generator(df):\n","    def generator():\n","        for book_idxs, book_idx, rating in zip(df.book_idxs, df.book_idx, df.rating):\n","            # Remove book_idx from book_idxs so the model can't just look it up.\n","            book_idxs = tuple(filter(lambda x: x != book_idx, book_idxs))\n","            yield {\n","                \"len_book_idxs\": len(book_idxs),\n","                \"book_idxs\": book_idxs,\n","                \"book_idx\": book_idx,\n","                \"label\": rating,\n","            }\n","            if rating == 1:\n","                # Generate a random negative book_id not in book_idxs.\n","                random_negative = np.random.randint(0, n_books)\n","                while random_negative in book_idxs:\n","                    random_negative = np.random.randint(0, n_books)\n","                yield {\n","                    \"len_book_idxs\": len(book_idxs),\n","                    \"book_idxs\": book_idxs,\n","                    \"book_idx\": random_negative,\n","                    \"label\": 0,\n","                }\n","\n","    return generator\n","\n","\n","def get_data_tensors(df):\n","    # Use generator to get data points each epoch, along with shuffling and batching.\n","    padded_shapes = {\n","        \"len_book_idxs\": [],\n","        \"book_idxs\": [None],\n","        \"book_idx\": [],\n","        \"label\": [],\n","    }\n","    dataset = (\n","        tf.data.Dataset.from_generator(\n","            get_data_points_generator(df), {k: tf.int64 for k in padded_shapes}\n","        )\n","        .shuffle(123)\n","        .repeat(None)\n","        .padded_batch(batch_size=256, padded_shapes=padded_shapes)\n","    )\n","    tensor_dict = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n","    return (\n","        (\n","            tensor_dict[\"len_book_idxs\"],\n","            tensor_dict[\"book_idxs\"],\n","            tensor_dict[\"book_idx\"],\n","        ),\n","        tensor_dict[\"label\"],\n","    )"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-41L56hOnZp7","executionInfo":{"status":"ok","timestamp":1637636124041,"user_tz":480,"elapsed":22635,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"5b8a2c02-bba1-4d60-f5b5-bbbc232a5b16"},"source":["#from utils import get_n_epochs\n","\n","model = get_model()\n","\n","X_train, Y_train = get_data_tensors(df_train_filtered)\n","X_valid, Y_valid = get_data_tensors(df_valid)\n","model.fit(\n","    X_train,\n","    Y_train,\n","    steps_per_epoch=300,\n","    validation_data=(X_valid, Y_valid),\n","    validation_steps=40,\n","    epochs=get_n_epochs(),\n","    verbose=1,\n",")"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","284/300 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5000 - f1_batch: 0.0951 - precision_batch: 0.0951 - recall_batch: 0.0951"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["300/300 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5000 - f1_batch: 0.0933 - precision_batch: 0.0933 - recall_batch: 0.0933 - val_loss: 0.6918 - val_accuracy: 0.5312 - val_f1_batch: 0.2244 - val_precision_batch: 0.2743 - val_recall_batch: 0.2352\n","Epoch 2/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5167 - f1_batch: 0.1567 - precision_batch: 0.1567 - recall_batch: 0.1567\n","Epoch 3/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5333 - f1_batch: 0.1433 - precision_batch: 0.1433 - recall_batch: 0.1433\n","Epoch 4/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5200 - f1_batch: 0.1633 - precision_batch: 0.1633 - recall_batch: 0.1633\n","Epoch 5/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5467 - f1_batch: 0.1767 - precision_batch: 0.1767 - recall_batch: 0.1767\n","Epoch 6/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5833 - f1_batch: 0.1900 - precision_batch: 0.1900 - recall_batch: 0.1900\n","Epoch 7/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5900 - f1_batch: 0.2133 - precision_batch: 0.2133 - recall_batch: 0.2133\n","Epoch 8/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5767 - f1_batch: 0.2067 - precision_batch: 0.2067 - recall_batch: 0.2067\n","Epoch 9/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6858 - accuracy: 0.6267 - f1_batch: 0.2467 - precision_batch: 0.2467 - recall_batch: 0.2467\n","Epoch 10/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.6400 - f1_batch: 0.2267 - precision_batch: 0.2267 - recall_batch: 0.2267\n","Epoch 11/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.6567 - f1_batch: 0.2667 - precision_batch: 0.2667 - recall_batch: 0.2667\n","Epoch 12/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.6633 - f1_batch: 0.2500 - precision_batch: 0.2500 - recall_batch: 0.2500\n","Epoch 13/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.7067 - f1_batch: 0.2900 - precision_batch: 0.2900 - recall_batch: 0.2900\n","Epoch 14/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6817 - accuracy: 0.7133 - f1_batch: 0.2867 - precision_batch: 0.2867 - recall_batch: 0.2867\n","Epoch 15/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6819 - accuracy: 0.7133 - f1_batch: 0.3100 - precision_batch: 0.3100 - recall_batch: 0.3100\n","Epoch 16/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6811 - accuracy: 0.7367 - f1_batch: 0.2967 - precision_batch: 0.2967 - recall_batch: 0.2967\n","Epoch 17/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6786 - accuracy: 0.7667 - f1_batch: 0.3133 - precision_batch: 0.3133 - recall_batch: 0.3133\n","Epoch 18/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6785 - accuracy: 0.7733 - f1_batch: 0.3367 - precision_batch: 0.3367 - recall_batch: 0.3367\n","Epoch 19/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6782 - accuracy: 0.7833 - f1_batch: 0.3267 - precision_batch: 0.3267 - recall_batch: 0.3267\n","Epoch 20/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6775 - accuracy: 0.8033 - f1_batch: 0.3767 - precision_batch: 0.3767 - recall_batch: 0.3767\n","Epoch 21/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6755 - accuracy: 0.7967 - f1_batch: 0.3400 - precision_batch: 0.3400 - recall_batch: 0.3400\n","Epoch 22/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.8267 - f1_batch: 0.3867 - precision_batch: 0.3867 - recall_batch: 0.3867\n","Epoch 23/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.8600 - f1_batch: 0.3933 - precision_batch: 0.3933 - recall_batch: 0.3933\n","Epoch 24/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6746 - accuracy: 0.8400 - f1_batch: 0.4033 - precision_batch: 0.4033 - recall_batch: 0.4033\n","Epoch 25/30\n","300/300 [==============================] - 1s 2ms/step - loss: 0.6731 - accuracy: 0.8533 - f1_batch: 0.3967 - precision_batch: 0.3967 - recall_batch: 0.3967\n","Epoch 26/30\n","159/300 [==============>...............] - ETA: 0s - loss: 0.6726 - accuracy: 0.8553 - f1_batch: 0.3774 - precision_batch: 0.3774 - recall_batch: 0.3774"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 9000 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.8611 - f1_batch: 0.3889 - precision_batch: 0.3889 - recall_batch: 0.3889\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f496c840c50>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZE9N6zDZne-e","executionInfo":{"status":"ok","timestamp":1637636125173,"user_tz":480,"elapsed":552,"user":{"displayName":"Raghava Devaraje Urs","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07685774915324699524"}},"outputId":"3bbca898-2ff4-467d-bb6d-8db96e1e08b0"},"source":["X_test, Y_test = get_data_tensors(df_test)\n","_ = model.evaluate(X_test, Y_test, steps=30)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["18/30 [=================>............] - ETA: 0s - loss: 0.6923 - accuracy: 0.5556 - f1_batch: 0.3984 - precision_batch: 0.5108 - recall_batch: 0.4014"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r30/30 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5312 - f1_batch: 0.3855 - precision_batch: 0.4668 - recall_batch: 0.4417\n"]}]}]}