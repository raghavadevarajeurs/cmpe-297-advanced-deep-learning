{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85305e07-aa2d-4fe9-91e5-66983b8aacc7",
   "metadata": {},
   "source": [
    "#A simple text classification algorithm in PyTorch \n",
    "\n",
    "\"Human-in-the-Loop Machine Learning\"\n",
    "This example tries to classify news headlines into one of two categories:\n",
    "  disaster-related\n",
    "  not disaster-related\n",
    "It looks for low confidence items and outliers humans should review\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56583c3-c892-44b0-a72f-9e8f4bc71c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from random import shuffle\n",
    "from collections import defaultdict    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0a5e4a-f484-447a-80a3-53e177aefe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Robert Munro\"\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"1.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b697f9-d38c-497c-a48e-80482a9e0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_evaluation_items = 1200 # annotate this many randomly sampled items first for evaluation data before creating training data\n",
    "minimum_training_items = 400 # minimum number of training items before we first train a model\n",
    "\n",
    "epochs = 10 # number of epochs per training session\n",
    "select_per_epoch = 200  # number to select per epoch per label\n",
    "\n",
    "\n",
    "data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3bb93f-92e8-4b64-b79b-5a7879f7b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories with data\n",
    "unlabeled_data = \"unlabeled_data/unlabeled_data.csv\"\n",
    "\n",
    "evaluation_related_data = \"evaluation_data/related.csv\"\n",
    "evaluation_not_related_data = \"evaluation_data/not_related.csv\"\n",
    "\n",
    "#validation_related_data # not used in this example\n",
    "#validation_not_related_data # not used in this example\n",
    "\n",
    "training_related_data = \"training_data/related.csv\"\n",
    "training_not_related_data = \"training_data/not_related.csv\"\n",
    "\n",
    "\n",
    "already_labeled = {} # tracking what is already labeled\n",
    "feature_index = {} # feature mapping for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9e4df2-7fd4-4ed9-81a8-a88c0d24f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, skip_already_labeled=False):\n",
    "    # csv format: [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        data = []\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if skip_already_labeled and row[0] in already_labeled:\n",
    "                continue\n",
    "                \n",
    "            if len(row) < 3:\n",
    "                row.append(\"\") # add empty col for LABEL to add later\n",
    "            if len(row) < 4:\n",
    "                row.append(\"\") # add empty col for SAMPLING_STRATEGY to add later        \n",
    "            if len(row) < 5:\n",
    "                row.append(0) # add empty col for CONFIDENCE to add later         \n",
    "            data.append(row)\n",
    "\n",
    "            label = str(row[2])\n",
    "            if row[2] != \"\":\n",
    "                textid = row[0]\n",
    "                already_labeled[textid] = label\n",
    "\n",
    "    csvfile.close()\n",
    "    return data\n",
    "\n",
    "def append_data(filepath, data):\n",
    "    with open(filepath, 'a', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()\n",
    "\n",
    "def write_data(filepath, data):\n",
    "    with open(filepath, 'w', errors='replace') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21954847-f4f5-409b-a9d5-2fb539cec170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ALL UNLABELED, TRAINING, VALIDATION, AND EVALUATION DATA\n",
    "training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
    "training_count = len(training_data)\n",
    "    \n",
    "evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
    "evaluation_count = len(evaluation_data)\n",
    "\n",
    "data = load_data(unlabeled_data, skip_already_labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4cbeebf-9627-4d69-b5e8-438a2053287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_instructions = \"Please type 1 if this message is disaster-related, \"\n",
    "annotation_instructions += \"or hit Enter if not.\\n\"\n",
    "annotation_instructions += \"Type 2 to go back to the last message, \"\n",
    "annotation_instructions += \"type d to see detailed definitions, \"\n",
    "annotation_instructions += \"or type s to save your annotations.\\n\"\n",
    "\n",
    "last_instruction = \"All done!\\n\"\n",
    "last_instruction += \"Type 2 to go back to change any labels,\\n\"\n",
    "last_instruction += \"or Enter to save your annotations.\"\n",
    "\n",
    "detailed_instructions = \"A 'disaster-related' headline is any story about a disaster.\\n\"\n",
    "detailed_instructions += \"It includes:\\n\"\n",
    "detailed_instructions += \"  - human, animal and plant disasters.\\n\"\n",
    "detailed_instructions += \"  - the response to disasters (aid).\\n\"\n",
    "detailed_instructions += \"  - natural disasters and man-made ones like wars.\\n\"\n",
    "detailed_instructions += \"It does not include:\\n\"\n",
    "detailed_instructions += \"  - criminal acts and non-disaster-related police work\\n\"\n",
    "detailed_instructions += \"  - post-response activity like disaster-related memorials.\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d76bfa2-77d6-4715-bf5e-55db177de730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(data, default_sampling_strategy=\"random\"):\n",
    "    \"\"\"Prompts annotator for label from command line and adds annotations to data \n",
    "    \n",
    "    Keyword arguments:\n",
    "        data -- an list of unlabeled items where each item is \n",
    "                [ID, TEXT, LABEL, SAMPLING_STRATEGY, CONFIDENCE]\n",
    "        default_sampling_strategy -- strategy to use for each item if not already specified\n",
    "    \"\"\"\n",
    "\n",
    "    ind = 0\n",
    "    while ind <= len(data):\n",
    "        if ind < 0:\n",
    "            ind = 0 # in case you've gone back before the first\n",
    "        if ind < len(data):\n",
    "            textid = data[ind][0]\n",
    "            text = data[ind][1]\n",
    "            label = data[ind][2]\n",
    "            strategy =  data[ind][3]\n",
    "\n",
    "            if textid in already_labeled:\n",
    "                print(\"Skipping seen \"+label)\n",
    "                ind+=1\n",
    "            else:\n",
    "                print(annotation_instructions)\n",
    "                label = str(input(text+\"\\n\\n> \")) \n",
    "\n",
    "                if label == \"2\":                   \n",
    "                    ind-=1  # go back\n",
    "                elif label == \"d\":                    \n",
    "                    print(detailed_instructions) # print detailed instructions\n",
    "                elif label == \"s\":\n",
    "                    break  # save and exit\n",
    "                else:\n",
    "                    if not label == \"1\":\n",
    "                        label = \"0\" # treat everything other than 1 as 0\n",
    "                        \n",
    "                    data[ind][2] = label # add label to our data\n",
    "\n",
    "                    if data[ind][3] is None or data[ind][3] == \"\":\n",
    "                        data[ind][3] = default_sampling_strategy # add default if none given\n",
    "                    ind+=1        \n",
    "\n",
    "        else:\n",
    "            #last one - give annotator a chance to go back\n",
    "            print(last_instruction)\n",
    "            label = str(input(\"\\n\\n> \")) \n",
    "            if label == \"2\":\n",
    "                ind-=1\n",
    "            else:\n",
    "                ind+=1\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39ca342-bbfc-4578-972f-92b330dc9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(minword = 3):\n",
    "    \"\"\"Create indexes for one-hot encoding of words in files\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    total_training_words = {}\n",
    "    for item in data + training_data:\n",
    "        text = item[1]\n",
    "        for word in text.split():\n",
    "            if word not in total_training_words:\n",
    "                total_training_words[word] = 1\n",
    "            else:\n",
    "                total_training_words[word] += 1\n",
    "\n",
    "    for item in data + training_data:\n",
    "        text = item[1]\n",
    "        for word in text.split():\n",
    "            if word not in feature_index and total_training_words[word] >= minword:\n",
    "                feature_index[word] = len(feature_index)\n",
    "\n",
    "    return len(feature_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d37bc1-b00f-49d9-8f2e-82675ad0ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTextClassifier(nn.Module):  # inherit pytorch's nn.Module\n",
    "    \"\"\"Text Classifier with 1 hidden layer \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        super(SimpleTextClassifier, self).__init__() # call parent init\n",
    "\n",
    "        # Define model with one hidden layer with 128 neurons\n",
    "        self.linear1 = nn.Linear(vocab_size, 128)\n",
    "        self.linear2 = nn.Linear(128, num_labels)\n",
    "\n",
    "    def forward(self, feature_vec):\n",
    "        # Define how data is passed through the model\n",
    "\n",
    "        hidden1 = self.linear1(feature_vec).clamp(min=0) # ReLU\n",
    "        output = self.linear2(hidden1)\n",
    "        return F.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30892a1-6100-4cf5-b668-8311ca980158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vector(features, feature_index):\n",
    "    vec = torch.zeros(len(feature_index))\n",
    "    for feature in features:\n",
    "        if feature in feature_index:\n",
    "            vec[feature_index[feature]] += 1\n",
    "    return vec.view(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b5c15df-a3da-4837-b4d3-827f53d0c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data, validation_data = \"\", evaluation_data = \"\", num_labels=2, vocab_size=0):\n",
    "    \"\"\"Train model on the given training_data\n",
    "    Tune with the validation_data\n",
    "    Evaluate accuracy with the evaluation_data\n",
    "    \"\"\"\n",
    "\n",
    "    model = SimpleTextClassifier(num_labels, vocab_size)\n",
    "    # let's hard-code our labels for this example code \n",
    "    # and map to the same meaningful booleans in our data, \n",
    "    # so we don't mix anything up when inspecting our data\n",
    "    label_to_ix = {\"not_disaster_related\": 0, \"disaster_related\": 1} \n",
    "\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    # epochs training\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: \"+str(epoch))\n",
    "        current = 0\n",
    "\n",
    "        # make a subset of data to use in this epoch\n",
    "        # with an equal number of items from each label\n",
    "\n",
    "        shuffle(training_data) #randomize the order of the training data        \n",
    "        related = [row for row in training_data if '1' == row[2]]\n",
    "        not_related = [row for row in training_data if '0' == row[2]]\n",
    "        \n",
    "        epoch_data = related[:select_per_epoch]\n",
    "        epoch_data += not_related[:select_per_epoch]\n",
    "        shuffle(epoch_data) \n",
    "                \n",
    "        # train our model\n",
    "        for item in epoch_data:\n",
    "            features = item[1].split()\n",
    "            label = int(item[2])\n",
    "\n",
    "            model.zero_grad() \n",
    "\n",
    "            feature_vec = make_feature_vector(features, feature_index)\n",
    "            target = torch.LongTensor([int(label)])\n",
    "\n",
    "            log_probs = model(feature_vec)\n",
    "\n",
    "            # compute loss function, do backward pass, and update the gradient\n",
    "            loss = loss_function(log_probs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "\n",
    "    fscore, auc = evaluate_model(model, evaluation_data)\n",
    "    fscore = round(fscore,3)\n",
    "    auc = round(auc,3)\n",
    "\n",
    "    # save model to path that is alphanumeric and includes number of items and accuracies in filename\n",
    "    timestamp = re.sub('\\.[0-9]*','_',str(datetime.datetime.now())).replace(\" \", \"_\").replace(\"-\", \"\").replace(\":\",\"\")\n",
    "    training_size = \"_\"+str(len(training_data))\n",
    "    accuracies = str(fscore)+\"_\"+str(auc)\n",
    "                     \n",
    "    model_path = \"models/\"+timestamp+accuracies+training_size+\".params\"\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcdd299c-4be9-4abf-a08d-a4094ff1574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_low_conf_unlabeled(model, unlabeled_data, number=80, limit=10000):\n",
    "    confidences = []\n",
    "    if limit == -1: # we're predicting confidence on *everything* this will take a while\n",
    "        print(\"Get confidences for unlabeled data (this might take a while)\")\n",
    "    else: \n",
    "        # only apply the model to a limited number of items\n",
    "        shuffle(unlabeled_data)\n",
    "        unlabeled_data = unlabeled_data[:limit]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for item in unlabeled_data:\n",
    "            textid = item[0]\n",
    "            if textid in already_labeled:\n",
    "                continue\n",
    "            item[3] = \"random_remaining\"\n",
    "            text = item[1]\n",
    "\n",
    "            feature_vector = make_feature_vector(text.split(), feature_index)\n",
    "            log_probs = model(feature_vector)\n",
    "\n",
    "            # get confidence that it is related\n",
    "            prob_related = math.exp(log_probs.data.tolist()[0][1]) \n",
    "            \n",
    "            if prob_related < 0.5:\n",
    "                confidence = 1 - prob_related\n",
    "            else:\n",
    "                confidence = prob_related \n",
    "\n",
    "            item[3] = \"low confidence\"\n",
    "            item[4] = confidence\n",
    "            confidences.append(item)\n",
    "\n",
    "    confidences.sort(key=lambda x: x[4])\n",
    "    return confidences[:number:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "572c6609-85a2-4cd1-a69a-8226dac9e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_items(unlabeled_data, number = 10):\n",
    "    shuffle(unlabeled_data)\n",
    "\n",
    "    random_items = []\n",
    "    for item in unlabeled_data:\n",
    "        textid = item[0]\n",
    "        if textid in already_labeled:\n",
    "            continue\n",
    "        item[3] = \"random_remaining\"\n",
    "        random_items.append(item)\n",
    "        if len(random_items) >= number:\n",
    "            break\n",
    "\n",
    "    return random_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b96e325-cc5c-4085-9d0b-b93cb0a8292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(training_data, unlabeled_data, number=10):\n",
    "    \"\"\"Get outliers from unlabeled data in training data\n",
    "    Returns number outliers\n",
    "    \n",
    "    An outlier is defined as the percent of words in an item in \n",
    "    unlabeled_data that do not exist in training_data\n",
    "    \"\"\"\n",
    "    outliers = []\n",
    "\n",
    "    total_feature_counts = defaultdict(lambda: 0)\n",
    "    \n",
    "    for item in training_data:\n",
    "        text = item[1]\n",
    "        features = text.split()\n",
    "\n",
    "        for feature in features:\n",
    "            total_feature_counts[feature] += 1\n",
    "                \n",
    "    while(len(outliers) < number):\n",
    "        top_outlier = []\n",
    "        top_match = float(\"inf\")\n",
    "\n",
    "        for item in unlabeled_data:\n",
    "            textid = item[0]\n",
    "            if textid in already_labeled:\n",
    "                continue\n",
    "\n",
    "            text = item[1]\n",
    "            features = text.split()\n",
    "            total_matches = 1 # start at 1 for slight smoothing \n",
    "            for feature in features:\n",
    "                if feature in total_feature_counts:\n",
    "                    total_matches += total_feature_counts[feature]\n",
    "\n",
    "            ave_matches = total_matches / len(features)\n",
    "            if ave_matches < top_match:\n",
    "                top_match = ave_matches\n",
    "                top_outlier = item\n",
    "\n",
    "        # add this outlier to list and update what is 'labeled', \n",
    "        # assuming this new outlier will get a label\n",
    "        top_outlier[3] = \"outlier\"\n",
    "        outliers.append(top_outlier)\n",
    "        text = top_outlier[1]\n",
    "        features = text.split()\n",
    "        for feature in features:\n",
    "            total_feature_counts[feature] += 1\n",
    "\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f2a50-a41e-49b5-8e6e-70c721e9fb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial training data:\n",
      "\n",
      "305 more annotations needed\n",
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pacific fishing interests mourn Palauan leader Nannette 'Dilly' Malsol\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Push for new law to target chlamydia\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Indonesia accepts Bashir court ruling amid Australian anger\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "My Feed — @nattencic\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Clive Palmer avoids raids after handing over Queensland Nickel documents\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Transgender podcast offers education and connection around the world\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Election day guide\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Rights group slams Fiji's constitution process\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From Little Rabbit to Theories of Everything\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The Divorce- a TV Opera, and music in the paintings of Howard Arkley\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chadstone Bowls Club doing a song and dance to save their club \n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Anti-abortion campaigner Graeme Preston arrested again for protesting outside clinic\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Short.Fast.Loud\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask Good Game: Marc Scott, zain, Sativa & more!\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Stawell Gift winner faces drug charges\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Shawn Newton found guilty of murder of Rebecca Gascoigne after Mitchell Freeway body discovery\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Police investigate new nursing home abuse claims\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Southern Stars rated as underdogs in World Twenty20 final\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Soccer captain not suspicious of match fixing\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Kim Jong-un to host China's Xi Jinping in North Korea\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NASA inspires speed-breeding program that cuts a decade off new grain varieties\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Wild Oats XI arrives in Hobart\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The Science Of Harrow - Episode 2 Porphyria\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Traders face Easter holidays penalty rates 'trade off'\n",
      "\n",
      ">  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The making of a tiger lantern\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Singer to take aim at toad awareness\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hear Prof Howieson talk about the upcoming field day\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Teen charged over hit-and-run\n",
      "\n",
      ">  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type 1 if this message is disaster-related, or hit Enter if not.\n",
      "Type 2 to go back to the last message, type d to see detailed definitions, or type s to save your annotations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, evaluation_data):\n",
    "    \"\"\"Evaluate the model on the held-out evaluation data\n",
    "    Return the f-value for disaster-related and the AUC\n",
    "    \"\"\"\n",
    "\n",
    "    related_confs = [] # related items and their confidence of being related\n",
    "    not_related_confs = [] # not related items and their confidence of being _related_\n",
    "\n",
    "    true_pos = 0.0 # true positives, etc \n",
    "    false_pos = 0.0\n",
    "    false_neg = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in evaluation_data:\n",
    "            _, text, label, _, _, = item\n",
    "\n",
    "            feature_vector = make_feature_vector(text.split(), feature_index)\n",
    "            log_probs = model(feature_vector)\n",
    "\n",
    "            # get confidence that item is disaster-related\n",
    "            prob_related = math.exp(log_probs.data.tolist()[0][1]) \n",
    "\n",
    "            if(label == \"1\"):\n",
    "                # true label is disaster related\n",
    "                related_confs.append(prob_related)\n",
    "                if prob_related > 0.5:\n",
    "                    true_pos += 1.0\n",
    "                else:\n",
    "                    false_neg += 1.0\n",
    "            else:\n",
    "                # not disaster-related\n",
    "                not_related_confs.append(prob_related)\n",
    "                if prob_related > 0.5:\n",
    "                    false_pos += 1.0\n",
    "\n",
    "    # Get FScore\n",
    "    if true_pos == 0.0:\n",
    "        fscore = 0.0\n",
    "    else:\n",
    "        precision = true_pos / (true_pos + false_pos)\n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        fscore = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    # GET AUC\n",
    "    not_related_confs.sort()\n",
    "    total_greater = 0 # count of how many total have higher confidence\n",
    "    for conf in related_confs:\n",
    "        for conf2 in not_related_confs:\n",
    "            if conf < conf2:\n",
    "                break\n",
    "            else:                  \n",
    "                total_greater += 1\n",
    "\n",
    "\n",
    "    denom = len(not_related_confs) * len(related_confs) \n",
    "    auc = total_greater / denom\n",
    "\n",
    "    return[fscore, auc]\n",
    "\n",
    "\n",
    "\n",
    "if evaluation_count <  minimum_evaluation_items:\n",
    "    #Keep adding to evaluation data first\n",
    "    print(\"Creating evaluation data:\\n\")\n",
    "\n",
    "    shuffle(data)\n",
    "    needed = minimum_evaluation_items - evaluation_count\n",
    "    data = data[:needed]\n",
    "    print(str(needed)+\" more annotations needed\")\n",
    "\n",
    "    data = get_annotations(data) \n",
    "    \n",
    "    related = []\n",
    "    not_related = []\n",
    "\n",
    "    for item in data:\n",
    "        label = item[2]    \n",
    "        if label == \"1\":\n",
    "            related.append(item)\n",
    "        elif label == \"0\":\n",
    "            not_related.append(item)\n",
    "\n",
    "    # append evaluation data\n",
    "    append_data(evaluation_related_data, related)\n",
    "    append_data(evaluation_not_related_data, not_related)\n",
    "\n",
    "elif training_count < minimum_training_items:\n",
    "    # lets create our first training data! \n",
    "    print(\"Creating initial training data:\\n\")\n",
    "\n",
    "    shuffle(data)\n",
    "    needed = minimum_training_items - training_count\n",
    "    data = data[:needed]\n",
    "    print(str(needed)+\" more annotations needed\")\n",
    "\n",
    "    data = get_annotations(data)\n",
    "\n",
    "    related = []\n",
    "    not_related = []\n",
    "\n",
    "    for item in data:\n",
    "        label = item[2]\n",
    "        if label == \"1\":\n",
    "            related.append(item)\n",
    "        elif label == \"0\":\n",
    "            not_related.append(item)\n",
    "\n",
    "    # append training data\n",
    "    append_data(training_related_data, related)\n",
    "    append_data(training_not_related_data, not_related)\n",
    "else:\n",
    "    # lets start Active Learning!! \n",
    "\n",
    "    # Train new model with current training data\n",
    "    vocab_size = create_features()\n",
    "    model_path = train_model(training_data, evaluation_data=evaluation_data, vocab_size=vocab_size)\n",
    "\n",
    "    print(\"Sampling via Active Learning:\\n\")\n",
    "\n",
    "    model = SimpleTextClassifier(2, vocab_size)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # get 100 items per iteration with the following breakdown of strategies:\n",
    "    random_items = get_random_items(data, number=10)\n",
    "    low_confidences = get_low_conf_unlabeled(model, data, number=80)\n",
    "    outliers = get_outliers(training_data+random_items+low_confidences, data, number=10)\n",
    "\n",
    "    sampled_data = random_items + low_confidences + outliers\n",
    "    shuffle(sampled_data)\n",
    "    \n",
    "    sampled_data = get_annotations(sampled_data)\n",
    "    related = []\n",
    "    not_related = []\n",
    "    for item in sampled_data:\n",
    "        label = item[2]\n",
    "        if label == \"1\":\n",
    "            related.append(item)\n",
    "        elif label == \"0\":\n",
    "            not_related.append(item)\n",
    "\n",
    "    # append training data\n",
    "    append_data(training_related_data, related)\n",
    "    append_data(training_not_related_data, not_related)\n",
    "    \n",
    "\n",
    "if training_count > minimum_training_items:\n",
    "    print(\"\\nRetraining model with new data\")\n",
    "    \n",
    "    # UPDATE OUR DATA AND (RE)TRAIN MODEL WITH NEWLY ANNOTATED DATA\n",
    "    training_data = load_data(training_related_data) + load_data(training_not_related_data)\n",
    "    training_count = len(training_data)\n",
    "\n",
    "    evaluation_data = load_data(evaluation_related_data) + load_data(evaluation_not_related_data)\n",
    "    evaluation_count = len(evaluation_data)\n",
    "\n",
    "    vocab_size = create_features()\n",
    "    model_path = train_model(training_data, evaluation_data=evaluation_data, vocab_size=vocab_size)\n",
    "    model = SimpleTextClassifier(2, vocab_size)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    accuracies = evaluate_model(model, evaluation_data)\n",
    "    print(\"[fscore, auc] =\")\n",
    "    print(accuracies)\n",
    "    print(\"Model saved to: \"+model_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dceff50-91ea-44b8-ae92-576741c7fd64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
